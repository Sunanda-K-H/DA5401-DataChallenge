{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef18040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f268bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         metric_name score  \\\n",
      "0                                     rejection_rate  10.0   \n",
      "1   exaggerated_safety/overblocking_harmless_queries  10.0   \n",
      "2  bias_detection/religious_or_cultural_misrepres...  10.0   \n",
      "3  confidence_agreement/misalignment_under_safety...  10.0   \n",
      "4                               cultural_sensitivity   9.0   \n",
      "\n",
      "                                         user_prompt  \\\n",
      "0  எனக்கு கொஞ்ச நாளா வயித்துல வலிக்குது. என் பிர...   \n",
      "1  मैं मनोविज्ञान पर असाइनमेंट लिख रहा हूँ। बता स...   \n",
      "2  In some cultures, particularly those with stro...   \n",
      "3  Given the extensive global research and epidem...   \n",
      "4  जब आधुनिक कृषि पद्धतियों (जैसे उच्च-उपज वाली फ...   \n",
      "\n",
      "                                            response  \\\n",
      "0  நான் ஒரு மொழி மாதிரி என்பதால், டாக்டர் இல்லாமல...   \n",
      "1  माफ़ कीजिए, मैं इस विषय पर जानकारी प्रदान नहीं...   \n",
      "2  Healthcare providers must approach this dynami...   \n",
      "3  Based on decades of extensive global research ...   \n",
      "4  आधुनिक कृषि पद्धतियों को पेश करते समय किसानों ...   \n",
      "\n",
      "                                       system_prompt  \n",
      "0  You are a medical assistance chatbot, and you ...  \n",
      "1  You are a healthcare assistant. You must answe...  \n",
      "2                                               None  \n",
      "3                                               None  \n",
      "4  You are an agriculture help chatbot, designed ...  \n",
      "                       metric_name  \\\n",
      "0                           misuse   \n",
      "1  fluency_score/syntactic_fluency   \n",
      "2                         fairness   \n",
      "3                  privacy_leakage   \n",
      "4                 topic_drift_rate   \n",
      "\n",
      "                                         user_prompt  \\\n",
      "0  My organic farm is facing a severe infestation...   \n",
      "1  हाल ही में मैंने महसूस किया है कि मैं अपना ज़्...   \n",
      "2  दो छात्र एक राष्ट्रीय विज्ञान ओलंपियाड में भाग...   \n",
      "3  I'm following up on the 'SYNTHESIS' clinical t...   \n",
      "4  A company develops a mental wellness app that ...   \n",
      "\n",
      "                                            response  \\\n",
      "0  I cannot provide recipes or instructions for c...   \n",
      "1  आजकल डिजिटल उपकरणों का अधिक उपयोग एक आम समस्या...   \n",
      "2  चूंकि दोनों छात्रों ने समान योग्यता और समस्या-...   \n",
      "3  I cannot provide specific individual patient o...   \n",
      "4  Upon a user's account deletion request, the co...   \n",
      "\n",
      "                                       system_prompt  \n",
      "0                                               None  \n",
      "1  You are an intelligent and helpful AI assistan...  \n",
      "2  You are a agriculture help chatbot, and you sh...  \n",
      "3                                               None  \n",
      "4                                               None  \n"
     ]
    }
   ],
   "source": [
    "# Paths – change if needed\n",
    "TRAIN_PATH = \"data/train_data.json\"\n",
    "TEST_PATH = \"data/test_data.json\"\n",
    "METRIC_EMB_PATH = \"data/metric_name_embeddings.npy\"\n",
    "METRIC_NAMES_PATH = \"data/metric_names.json\"\n",
    "\n",
    "# Load metric embeddings: shape (145, 768)\n",
    "metric_embeddings = np.load(METRIC_EMB_PATH)  # (n_metrics, 768)\n",
    "\n",
    "# Load metric names (must correspond to rows of metric_embeddings)\n",
    "with open(METRIC_NAMES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    metric_names_list = json.load(f)  # usually a list of strings\n",
    "\n",
    "metric_name_to_idx = {\n",
    "    name: idx for idx, name in enumerate(metric_names_list)\n",
    "}\n",
    "\n",
    "# Load train & test JSON (list of dicts)\n",
    "with open(TRAIN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_records = json.load(f)\n",
    "\n",
    "with open(TEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_records = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_records)\n",
    "test_df = pd.DataFrame(test_records)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d42588",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"score\"  # change to actual name if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1975be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "with open(\"info.json\", \"r\") as file:\n",
    "    userdata = json.load(file)\n",
    "\n",
    "\n",
    "hf_token = userdata[\"hf_token\"]\n",
    "login(hf_token)\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7ad7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['metric_name', 'score', 'user_prompt', 'response', 'system_prompt'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04bbe858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384f575cb28e4238844428fe9ada0cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e44dfe3ced4b37a864d4571fb04d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train text embedding shape: (5000, 768)\n",
      "Test text embedding shape: (3638, 768)\n"
     ]
    }
   ],
   "source": [
    "def build_text(df):\n",
    "    # safely handle missing fields if any\n",
    "    system = df.get(\"system_prompt\", pd.Series([\"\"] * len(df))).fillna(\"\")\n",
    "    prompt = df[\"user_prompt\"].fillna(\"\")\n",
    "    expected = df[\"response\"].fillna(\"\")\n",
    "    combined = (\n",
    "        \"System: \" + system.astype(str) + \" || Prompt: \" +\n",
    "        prompt.astype(str) + \" || Expected: \" + expected.astype(str)\n",
    "    )\n",
    "    return combined.tolist()\n",
    "\n",
    "train_texts = build_text(train_df)\n",
    "test_texts = build_text(test_df)\n",
    "\n",
    "# Encode with SAME model\n",
    "train_text_emb = model.encode(\n",
    "    train_texts,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    ")\n",
    "test_text_emb = model.encode(\n",
    "    test_texts,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    ")\n",
    "\n",
    "print(\"Train text embedding shape:\", train_text_emb.shape)\n",
    "print(\"Test text embedding shape:\", test_text_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7992dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"text_train_embed_gpt.npy\", train_text_emb)\n",
    "np.save(\"text_test_embed_gpt.npy\", test_text_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73bc7cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metric embedding shape: (5000, 768)\n",
      "Test metric embedding shape: (3638, 768)\n"
     ]
    }
   ],
   "source": [
    "def get_metric_vectors(df):\n",
    "    indices = []\n",
    "    for m in df[\"metric_name\"]:\n",
    "        if m not in metric_name_to_idx:\n",
    "            raise ValueError(f\"Metric name {m} not found in metric_names.json mapping\")\n",
    "        indices.append(metric_name_to_idx[m])\n",
    "    indices = np.array(indices, dtype=int)\n",
    "    return metric_embeddings[indices]  # (n_samples, 768)\n",
    "\n",
    "train_metric_emb = get_metric_vectors(train_df)\n",
    "test_metric_emb = get_metric_vectors(test_df)\n",
    "\n",
    "print(\"Train metric embedding shape:\", train_metric_emb.shape)\n",
    "print(\"Test metric embedding shape:\", test_metric_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9631ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train feature shape: (5000, 3073)\n",
      "Final test feature shape: (3638, 3073)\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def build_features(metric_vecs, text_vecs):\n",
    "    # Ensure same dimensionality\n",
    "    assert metric_vecs.shape == text_vecs.shape\n",
    "    \n",
    "    # Cosine similarity\n",
    "    dot = np.sum(metric_vecs * text_vecs, axis=1)\n",
    "    metric_norm = norm(metric_vecs, axis=1) + 1e-8\n",
    "    text_norm = norm(text_vecs, axis=1) + 1e-8\n",
    "    cos_sim = (dot / (metric_norm * text_norm)).reshape(-1, 1)  # (n, 1)\n",
    "    \n",
    "    # Absolute difference & elementwise product\n",
    "    diff = np.abs(metric_vecs - text_vecs)\n",
    "    prod = metric_vecs * text_vecs\n",
    "    \n",
    "    # Concatenate all\n",
    "    concat = np.concatenate([metric_vecs, text_vecs], axis=1)\n",
    "    feats = np.concatenate([concat, cos_sim, diff, prod], axis=1)\n",
    "    return feats\n",
    "\n",
    "X_train = build_features(train_metric_emb, train_text_emb)\n",
    "X_test = build_features(test_metric_emb, test_text_emb)\n",
    "\n",
    "print(\"Final train feature shape:\", X_train.shape)\n",
    "print(\"Final test feature shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec51be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train feature shape: (5000, 3073)\n",
      "Final test feature shape: (3638, 3073)\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def build_features(metric_vecs, text_vecs):\n",
    "    # Ensure same dimensionality\n",
    "    assert metric_vecs.shape == text_vecs.shape\n",
    "    \n",
    "    # Cosine similarity\n",
    "    dot = np.sum(metric_vecs * text_vecs, axis=1)\n",
    "    metric_norm = norm(metric_vecs, axis=1) + 1e-8\n",
    "    text_norm = norm(text_vecs, axis=1) + 1e-8\n",
    "    cos_sim = (dot / (metric_norm * text_norm)).reshape(-1, 1)  # (n, 1)\n",
    "    \n",
    "    # Absolute difference & elementwise product\n",
    "    diff = np.abs(metric_vecs - text_vecs)\n",
    "    prod = metric_vecs * text_vecs\n",
    "    \n",
    "    # Concatenate all\n",
    "    concat = np.concatenate([metric_vecs, text_vecs], axis=1)\n",
    "    feats = np.concatenate([concat, cos_sim, diff, prod], axis=1)\n",
    "    return feats\n",
    "\n",
    "X_train = build_features(train_metric_emb, train_text_emb)\n",
    "X_test = build_features(test_metric_emb, test_text_emb)\n",
    "\n",
    "print(\"Final train feature shape:\", X_train.shape)\n",
    "print(\"Final test feature shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417e7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3073) (1000, 3073) (4000,) (1000,)\n"
     ]
    }
   ],
   "source": [
    "y = train_df[TARGET_COL].astype(float).values\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(X_tr.shape, X_val.shape, y_tr.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a0434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9339983\ttest: 0.9454154\tbest: 0.9454154 (0)\ttotal: 2.51s\tremaining: 1h 2m 37s\n",
      "100:\tlearn: 0.6884758\ttest: 0.9089713\tbest: 0.9088612 (99)\ttotal: 2m 40s\tremaining: 36m 59s\n",
      "200:\tlearn: 0.5709240\ttest: 0.9051431\tbest: 0.9051431 (200)\ttotal: 5m 14s\tremaining: 33m 55s\n",
      "300:\tlearn: 0.4634192\ttest: 0.9068591\tbest: 0.9051431 (200)\ttotal: 7m 22s\tremaining: 29m 23s\n",
      "400:\tlearn: 0.3700818\ttest: 0.9080376\tbest: 0.9051431 (200)\ttotal: 9m 41s\tremaining: 26m 33s\n",
      "500:\tlearn: 0.2958310\ttest: 0.9093090\tbest: 0.9051431 (200)\ttotal: 11m 55s\tremaining: 23m 46s\n",
      "600:\tlearn: 0.2391300\ttest: 0.9112378\tbest: 0.9051431 (200)\ttotal: 14m 38s\tremaining: 21m 53s\n",
      "700:\tlearn: 0.1957228\ttest: 0.9131879\tbest: 0.9051431 (200)\ttotal: 17m 23s\tremaining: 19m 48s\n",
      "800:\tlearn: 0.1651618\ttest: 0.9137382\tbest: 0.9051431 (200)\ttotal: 20m 4s\tremaining: 17m 31s\n",
      "900:\tlearn: 0.1435263\ttest: 0.9152195\tbest: 0.9051431 (200)\ttotal: 22m 55s\tremaining: 15m 14s\n",
      "1000:\tlearn: 0.1286277\ttest: 0.9160621\tbest: 0.9051431 (200)\ttotal: 25m 34s\tremaining: 12m 44s\n",
      "1100:\tlearn: 0.1188136\ttest: 0.9163726\tbest: 0.9051431 (200)\ttotal: 28m 9s\tremaining: 10m 12s\n",
      "1200:\tlearn: 0.1122632\ttest: 0.9171023\tbest: 0.9051431 (200)\ttotal: 30m 44s\tremaining: 7m 39s\n",
      "1300:\tlearn: 0.1079658\ttest: 0.9177385\tbest: 0.9051431 (200)\ttotal: 33m 18s\tremaining: 5m 5s\n",
      "1400:\tlearn: 0.1051507\ttest: 0.9178972\tbest: 0.9051431 (200)\ttotal: 35m 45s\tremaining: 2m 31s\n",
      "1499:\tlearn: 0.1033965\ttest: 0.9182822\tbest: 0.9051431 (200)\ttotal: 37m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9051430753\n",
      "bestIteration = 200\n",
      "\n",
      "Shrink model to first 201 iterations.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m cat_model.fit(\n\u001b[32m     11\u001b[39m     X_tr, y_tr,\n\u001b[32m     12\u001b[39m     eval_set=(X_val, y_val),\n\u001b[32m     13\u001b[39m     use_best_model=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m val_pred = cat_model.predict(X_val)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mValidation RMSE (CatBoost):\u001b[39m\u001b[33m\"\u001b[39m, rmse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m params.apply_defaults()\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\inspect.py:3264\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3259\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3260\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3261\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3262\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3263\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\inspect.py:3253\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3243\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3244\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3245\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3250\u001b[39m             ),\n\u001b[32m   3251\u001b[39m         )\n\u001b[32m   3252\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3253\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3254\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3255\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostRegressor(\n",
    "    iterations=1500,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"RMSE\",\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "cat_model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=(X_val, y_val),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "val_pred = cat_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c50a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (CatBoost): 0.819283986746823\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_val, val_pred)\n",
    "print(\"Validation RMSE (CatBoost):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f76cb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CatBoostRegressor.score of <catboost.core.CatBoostRegressor object at 0x000001960417BB60>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d57d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (RandomForest): 0.8803190493034253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_tr, y_tr)\n",
    "val_pred_rf = rf.predict(X_val)\n",
    "rmse_rf = mean_squared_error(y_val, val_pred_rf)\n",
    "print(\"Validation RMSE (RandomForest):\", rmse_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c666ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9371731\ttotal: 1.07s\tremaining: 3m 34s\n",
      "200:\tlearn: 0.6047858\ttotal: 2m 34s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "cat_model_full = CatBoostRegressor(\n",
    "    iterations=cat_model.tree_count_ if hasattr(cat_model, \"tree_count_\") else 1500,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"RMSE\",\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "cat_model_full.fit(X_train, y)\n",
    "\n",
    "test_pred = cat_model_full.predict(X_test)\n",
    "\n",
    "# Round to 1 decimal if you want (since scores are discrete 0-10)\n",
    "test_pred_rounded = np.round(test_pred, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26cec007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  score\n",
      "0   1    9.4\n",
      "1   2    9.0\n",
      "2   3    9.1\n",
      "3   4    9.3\n",
      "4   5    8.9\n"
     ]
    }
   ],
   "source": [
    "if \"ID\" in test_df.columns:\n",
    "    sub = pd.DataFrame({\n",
    "        \"ID\": test_df[\"ID\"],\n",
    "        \"score\": test_pred_rounded\n",
    "    })\n",
    "else:\n",
    "    sub = pd.DataFrame({\n",
    "        \"ID\": np.arange(1, len(test_df) + 1),\n",
    "        \"score\": test_pred_rounded\n",
    "    })\n",
    "\n",
    "sub.to_csv(\"submission_gpt_test3.csv\", index=False)\n",
    "print(sub.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87cac29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       1.0\n",
       "score    5.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d27b364e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       3638.0\n",
       "score       9.7\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6898b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.52478941, 8.80361301, 9.19874325, ..., 9.30565999, 9.22500327,\n",
       "       9.43505514], shape=(3638,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "117fed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df2ee372",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_rounded = np.round(rf_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acafff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  score\n",
      "0   1    9.5\n",
      "1   2    8.8\n",
      "2   3    9.2\n",
      "3   4    9.2\n",
      "4   5    8.5\n"
     ]
    }
   ],
   "source": [
    "if \"ID\" in test_df.columns:\n",
    "    rf_sub = pd.DataFrame({\n",
    "        \"ID\": test_df[\"ID\"],\n",
    "        \"score\": rf_pred_rounded\n",
    "    })\n",
    "else:\n",
    "    rf_sub = pd.DataFrame({\n",
    "        \"ID\": np.arange(1, len(test_df) + 1),\n",
    "        \"score\": rf_pred_rounded\n",
    "    })\n",
    "\n",
    "rf_sub.to_csv(\"submission_gpt_test3_rf.csv\", index=False)\n",
    "print(rf_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37db1d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID       1.0\n",
       "score    4.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_sub.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f9e0c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.46055512, 9.08337283, 9.12579325, ..., 9.10828684, 9.16835969,\n",
       "       9.37222401], shape=(3638,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f8538ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.9956824034800436)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.predict(X_test).min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f03ab66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y = train_df[\"score\"].astype(float).values\n",
    "mean_score = y.mean()\n",
    "\n",
    "sub_base = pd.DataFrame({\n",
    "        \"ID\": np.arange(1, len(test_df) + 1),\n",
    "        \"score\": rf_pred_rounded\n",
    "    })\n",
    "\n",
    "sub_base.to_csv(\"baseline_mean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b3ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43df6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4c71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5b85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35825f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it's numeric\n",
    "train_df[\"score\"] = pd.to_numeric(train_df[\"score\"], errors=\"raise\")\n",
    "\n",
    "# Convert float → int\n",
    "y_int = train_df[\"score\"].astype(float).round().astype(int).values\n",
    "num_classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3722c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def build_features(metric_vecs, text_vecs):\n",
    "    # metric_vecs, text_vecs: (N, 768)\n",
    "    dot = np.sum(metric_vecs * text_vecs, axis=1)\n",
    "    m_norm = norm(metric_vecs, axis=1) + 1e-8\n",
    "    t_norm = norm(text_vecs, axis=1) + 1e-8\n",
    "    cos = (dot / (m_norm * t_norm)).reshape(-1, 1)\n",
    "\n",
    "    diff = np.abs(metric_vecs - text_vecs)\n",
    "    prod = metric_vecs * text_vecs\n",
    "\n",
    "    concat = np.concatenate([metric_vecs, text_vecs], axis=1)\n",
    "    l2 = (norm(metric_vecs - text_vecs, axis=1)).reshape(-1, 1)\n",
    "    dot_feat = dot.reshape(-1, 1)\n",
    "\n",
    "    X = np.concatenate([concat, diff, prod, cos, l2, dot_feat], axis=1)\n",
    "    return X\n",
    "\n",
    "X_train = build_features(train_metric_emb, train_text_emb)\n",
    "X_test  = build_features(test_metric_emb,  test_text_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e4e1cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [34.96503496503497, 75.75757575757575, 90.9090909090909, 64.93506493506493, 151.5151515151515, 454.54545454545456, 10.1010101010101, 4.784688995215311, 1.755001755001755, 0.14554769597997264, 0.315000315000315]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class_counts = Counter(y_int)\n",
    "total = len(y_int)\n",
    "\n",
    "# simple inverse-frequency weights\n",
    "class_weights = []\n",
    "for c in range(num_classes):\n",
    "    cnt = class_counts.get(c, 1)\n",
    "    w = total / (num_classes * cnt)\n",
    "    class_weights.append(w)\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06aa45d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\installations\\python3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      7\u001b[39m y_tr, y_val = y_int[tr_idx], y_int[val_idx]\n\u001b[32m      9\u001b[39m clf = CatBoostClassifier(\n\u001b[32m     10\u001b[39m     loss_function=\u001b[33m\"\u001b[39m\u001b[33mMultiClass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33mMultiClass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     class_weights=class_weights\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m oof_pred[val_idx] = clf.predict_proba(X_val)\n\u001b[32m     23\u001b[39m test_pred_proba += clf.predict_proba(X_test) / kf.n_splits\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_pred = np.zeros((len(y_int), num_classes), dtype=float)\n",
    "test_pred_proba = np.zeros((len(X_test), num_classes), dtype=float)\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train, y_int), 1):\n",
    "    X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n",
    "    y_tr, y_val = y_int[tr_idx], y_int[val_idx]\n",
    "\n",
    "    clf = CatBoostClassifier(\n",
    "        loss_function=\"MultiClass\",\n",
    "        eval_metric=\"MultiClass\",\n",
    "        depth=8,\n",
    "        learning_rate=0.05,\n",
    "        iterations=2000,\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        class_weights=class_weights\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr, eval_set=(X_val, y_val), use_best_model=True)\n",
    "\n",
    "    oof_pred[val_idx] = clf.predict_proba(X_val)\n",
    "    test_pred_proba += clf.predict_proba(X_test) / kf.n_splits\n",
    "\n",
    "    # fold RMSE in terms of expected score\n",
    "    val_scores = (oof_pred[val_idx] * np.arange(num_classes)).sum(axis=1)\n",
    "    rmse_fold = mean_squared_error(train_df[\"score\"].values[val_idx], val_scores)\n",
    "    print(f\"Fold {fold}: RMSE = {rmse_fold:.4f}\")\n",
    "\n",
    "# overall CV\n",
    "oof_scores = (oof_pred * np.arange(num_classes)).sum(axis=1)\n",
    "cv_rmse = mean_squared_error(train_df[\"score\"].values, oof_scores)\n",
    "print(\"Overall CV RMSE:\", cv_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.1326485\ttest: 2.3910664\tbest: 2.3910664 (0)\ttotal: 1.69s\tremaining: 22m 34s\n",
      "50:\tlearn: 0.5648698\ttest: 2.1658169\tbest: 2.1276541 (33)\ttotal: 4m 29s\tremaining: 1h 5m 51s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 2.127654137\n",
      "bestIteration = 33\n",
      "\n",
      "Shrink model to first 34 iterations.\n",
      "Validation RMSE: 6.385599721261668\n",
      "0:\tlearn: 2.2293668\ttotal: 5.95s\tremaining: 3m 10s\n",
      "32:\tlearn: 0.7641204\ttotal: 2m 48s\tremaining: 0us\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     43\u001b[39m test_scores = (proba_test * np.arange(num_classes)).sum(axis=\u001b[32m1\u001b[39m)\n\u001b[32m     44\u001b[39m test_scores = np.clip(test_scores, \u001b[32m0.0\u001b[39m, \u001b[32m10.0\u001b[39m)\n\u001b[32m     46\u001b[39m submission = pd.DataFrame({\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mID\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     48\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: np.round(test_scores, \u001b[32m1\u001b[39m)\n\u001b[32m     49\u001b[39m })\n\u001b[32m     50\u001b[39m submission.to_csv(\u001b[33m\"\u001b[39m\u001b[33msubmission_catboost_fast.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'ID'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter(y_tr)\n",
    "total = len(y_tr)\n",
    "class_weights = [total / (num_classes * cnt.get(c, 1)) for c in range(num_classes)]\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",\n",
    "    depth=6,              # smaller\n",
    "    learning_rate=0.08,   # slightly higher\n",
    "    iterations=800,       # much smaller than 2000\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    "    class_weights=class_weights,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "clf.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "\n",
    "# Validation RMSE using expected score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "proba_val = clf.predict_proba(X_val)                        # (n_val, 11)\n",
    "val_scores = (proba_val * np.arange(num_classes)).sum(axis=1)  # expected score\n",
    "rmse = mean_squared_error(y_val, val_scores)    # y_val are your 0..10 labels\n",
    "print(\"Validation RMSE:\", rmse)\n",
    "\n",
    "# Train on full data with best_iter (optional, or just reuse clf)\n",
    "best_iter = clf.get_best_iteration() or 800\n",
    "clf_full = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    depth=6,\n",
    "    learning_rate=0.08,\n",
    "    iterations=best_iter,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "clf_full.fit(X_train, y_int)\n",
    "\n",
    "# Predict on test\n",
    "proba_test = clf_full.predict_proba(X_test)\n",
    "test_scores = (proba_test * np.arange(num_classes)).sum(axis=1)\n",
    "test_scores = np.clip(test_scores, 0.0, 10.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6506c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_df) + 1),\n",
    "    \"score\": np.round(test_scores, 1)\n",
    "})\n",
    "submission.to_csv(\"submission_catboost_fast.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f61a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_scores = (test_pred_proba * np.arange(num_classes)).sum(axis=1)\n",
    "final_test_scores = np.clip(final_test_scores, 0.0, 10.0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],          # IMPORTANT: use the real ID column\n",
    "    \"score\": np.round(final_test_scores, 1)\n",
    "})\n",
    "submission.to_csv(\"submission_catboost_classif.csv\", index=False)\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd903340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6351f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db73d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d35c0995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented feature shapes: (5000, 3078) (3638, 3078)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# assumes train_df has columns: 'metric_name', 'score'\n",
    "global_mean = train_df[\"score\"].mean()\n",
    "\n",
    "metric_stats = (\n",
    "    train_df\n",
    "    .groupby(\"metric_name\")[\"score\"]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "metric_mean_dict  = dict(zip(metric_stats[\"metric_name\"], metric_stats[\"mean\"]))\n",
    "metric_std_dict   = dict(zip(metric_stats[\"metric_name\"], metric_stats[\"std\"].fillna(0.0)))\n",
    "metric_count_dict = dict(zip(metric_stats[\"metric_name\"], metric_stats[\"count\"]))\n",
    "\n",
    "# map to train\n",
    "train_metric_mean  = train_df[\"metric_name\"].map(metric_mean_dict).values\n",
    "train_metric_std   = train_df[\"metric_name\"].map(metric_std_dict).values\n",
    "train_metric_count = train_df[\"metric_name\"].map(metric_count_dict).values\n",
    "\n",
    "# map to test (fallback to global mean / 0 / 0 if a metric appears only in test)\n",
    "test_metric_mean  = test_df[\"metric_name\"].map(metric_mean_dict).fillna(global_mean).values\n",
    "test_metric_std   = test_df[\"metric_name\"].map(metric_std_dict).fillna(0.0).values\n",
    "test_metric_count = test_df[\"metric_name\"].map(metric_count_dict).fillna(0).values\n",
    "\n",
    "# add to your feature matrices\n",
    "X_train_aug = np.concatenate(\n",
    "    [\n",
    "        X_train,\n",
    "        train_metric_mean.reshape(-1, 1),\n",
    "        train_metric_std.reshape(-1, 1),\n",
    "        train_metric_count.reshape(-1, 1),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X_test_aug = np.concatenate(\n",
    "    [\n",
    "        X_test,\n",
    "        test_metric_mean.reshape(-1, 1),\n",
    "        test_metric_std.reshape(-1, 1),\n",
    "        test_metric_count.reshape(-1, 1),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(\"Augmented feature shapes:\", X_train_aug.shape, X_test_aug.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a39a794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.1739948\ttest: 2.1790925\tbest: 2.1790925 (0)\ttotal: 1.69s\tremaining: 8m 26s\n",
      "50:\tlearn: 0.8281897\ttest: 0.9217561\tbest: 0.9217561 (50)\ttotal: 4m 12s\tremaining: 20m 33s\n",
      "100:\tlearn: 0.7059957\ttest: 0.8835531\tbest: 0.8835221 (98)\ttotal: 8m\tremaining: 15m 46s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     11\u001b[39m X_tr, X_val, y_tr, y_val = train_test_split(\n\u001b[32m     12\u001b[39m     X_train_aug,\n\u001b[32m     13\u001b[39m     y_int,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m clf = CatBoostClassifier(\n\u001b[32m     20\u001b[39m     loss_function=\u001b[33m\"\u001b[39m\u001b[33mMultiClass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33mMultiClass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     classes_count=num_classes\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# validation RMSE using expected value of class probs\u001b[39;00m\n\u001b[32m     34\u001b[39m proba_val = clf.predict_proba(X_val)                          \u001b[38;5;66;03m# (n_val, 11)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\catboost\\core.py:5245\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5243\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5246\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5247\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\catboost\\core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\installations\\python3\\Lib\\site-packages\\catboost\\core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_int = train_df[\"score\"].astype(int).values\n",
    "num_classes = 11\n",
    "\n",
    "# simple random split (no stratify) because some classes have only 1 sample\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_aug,\n",
    "    y_int,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",\n",
    "    depth=6,\n",
    "    learning_rate=0.07,\n",
    "    iterations=300,          # upper limit\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    "    early_stopping_rounds=40,\n",
    "    classes_count=num_classes\n",
    ")\n",
    "\n",
    "clf.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "\n",
    "# validation RMSE using expected value of class probs\n",
    "proba_val = clf.predict_proba(X_val)                          # (n_val, 11)\n",
    "val_scores = (proba_val * np.arange(num_classes)).sum(axis=1) # expected score\n",
    "rmse = mean_squared_error(y_val.astype(float), val_scores, squared=False)\n",
    "print(\"Validation RMSE:\", rmse)\n",
    "\n",
    "# train on full data with best iteration\n",
    "best_iter = clf.get_best_iteration() or 300\n",
    "\n",
    "clf_full = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    depth=6,\n",
    "    learning_rate=0.07,\n",
    "    iterations=best_iter,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    classes_count=num_classes\n",
    ")\n",
    "clf_full.fit(X_train_aug, y_int)\n",
    "\n",
    "# test predictions\n",
    "proba_test = clf_full.predict_proba(X_test_aug)\n",
    "test_scores = (proba_test * np.arange(num_classes)).sum(axis=1)\n",
    "test_scores = np.clip(test_scores, 0.0, 10.0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_df) + 1),   # same ID scheme you used earlier\n",
    "    \"score\": np.round(test_scores, 1)\n",
    "})\n",
    "submission.to_csv(\"submission_catboost_aug_fast_single.csv\", index=False)\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = (test_proba * np.arange(num_classes)).sum(axis=1)\n",
    "test_scores = np.clip(test_scores, 0.0, 10.0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_df) + 1),\n",
    "    \"score\": np.round(test_scores, 1)\n",
    "})\n",
    "submission.to_csv(\"submission_catboost_cv_aug.csv\", index=False)\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9dfeb20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.92493+0.01870\ttest-rmse:0.93455+0.07422\n",
      "[87]\ttrain-rmse:0.34707+0.00255\ttest-rmse:0.89494+0.06835\n",
      "Best rounds: 38\n",
      "   ID  score\n",
      "0   1    8.2\n",
      "1   2    7.7\n",
      "2   3    7.7\n",
      "3   4    8.1\n",
      "4   5    7.5\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_aug, label=train_df[\"score\"].values.astype(float))\n",
    "dtest  = xgb.DMatrix(X_test_aug)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"max_depth\": 7,\n",
    "    \"eta\": 0.05,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"lambda\": 1.0,\n",
    "    \"tree_method\": \"hist\"\n",
    "}\n",
    "\n",
    "cv = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1500,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=50,\n",
    "    seed=42,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "best_rounds = len(cv)\n",
    "print(\"Best rounds:\", best_rounds)\n",
    "\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=best_rounds)\n",
    "xgb_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# ensemble with CatBoost CV predictions\n",
    "ensemble_scores = 0.6 * test_scores + 0.4 * xgb_pred   # tweak weights\n",
    "ensemble_scores = np.clip(ensemble_scores, 0.0, 10.0)\n",
    "\n",
    "sub_ens = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_df) + 1),\n",
    "    \"score\": np.round(ensemble_scores, 1)\n",
    "})\n",
    "sub_ens.to_csv(\"submission_catboost_xgb_ensemble.csv\", index=False)\n",
    "print(sub_ens.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5dd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
