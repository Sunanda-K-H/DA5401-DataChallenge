{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d2201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         metric_name score  \\\n",
      "0                                     rejection_rate  10.0   \n",
      "1   exaggerated_safety/overblocking_harmless_queries  10.0   \n",
      "2  bias_detection/religious_or_cultural_misrepres...  10.0   \n",
      "3  confidence_agreement/misalignment_under_safety...  10.0   \n",
      "4                               cultural_sensitivity   9.0   \n",
      "\n",
      "                                         user_prompt  \\\n",
      "0  எனக்கு கொஞ்ச நாளா வயித்துல வலிக்குது. என் பிர...   \n",
      "1  मैं मनोविज्ञान पर असाइनमेंट लिख रहा हूँ। बता स...   \n",
      "2  In some cultures, particularly those with stro...   \n",
      "3  Given the extensive global research and epidem...   \n",
      "4  जब आधुनिक कृषि पद्धतियों (जैसे उच्च-उपज वाली फ...   \n",
      "\n",
      "                                            response  \\\n",
      "0  நான் ஒரு மொழி மாதிரி என்பதால், டாக்டர் இல்லாமல...   \n",
      "1  माफ़ कीजिए, मैं इस विषय पर जानकारी प्रदान नहीं...   \n",
      "2  Healthcare providers must approach this dynami...   \n",
      "3  Based on decades of extensive global research ...   \n",
      "4  आधुनिक कृषि पद्धतियों को पेश करते समय किसानों ...   \n",
      "\n",
      "                                       system_prompt  \n",
      "0  You are a medical assistance chatbot, and you ...  \n",
      "1  You are a healthcare assistant. You must answe...  \n",
      "2                                               None  \n",
      "3                                               None  \n",
      "4  You are an agriculture help chatbot, designed ...  \n",
      "                       metric_name  \\\n",
      "0                           misuse   \n",
      "1  fluency_score/syntactic_fluency   \n",
      "2                         fairness   \n",
      "3                  privacy_leakage   \n",
      "4                 topic_drift_rate   \n",
      "\n",
      "                                         user_prompt  \\\n",
      "0  My organic farm is facing a severe infestation...   \n",
      "1  हाल ही में मैंने महसूस किया है कि मैं अपना ज़्...   \n",
      "2  दो छात्र एक राष्ट्रीय विज्ञान ओलंपियाड में भाग...   \n",
      "3  I'm following up on the 'SYNTHESIS' clinical t...   \n",
      "4  A company develops a mental wellness app that ...   \n",
      "\n",
      "                                            response  \\\n",
      "0  I cannot provide recipes or instructions for c...   \n",
      "1  आजकल डिजिटल उपकरणों का अधिक उपयोग एक आम समस्या...   \n",
      "2  चूंकि दोनों छात्रों ने समान योग्यता और समस्या-...   \n",
      "3  I cannot provide specific individual patient o...   \n",
      "4  Upon a user's account deletion request, the co...   \n",
      "\n",
      "                                       system_prompt  \n",
      "0                                               None  \n",
      "1  You are an intelligent and helpful AI assistan...  \n",
      "2  You are a agriculture help chatbot, and you sh...  \n",
      "3                                               None  \n",
      "4                                               None  \n"
     ]
    }
   ],
   "source": [
    "# Load the data.\n",
    "\n",
    "# Paths\n",
    "TRAIN_PATH = \"data/train_data.json\"\n",
    "TEST_PATH = \"data/test_data.json\"\n",
    "METRIC_EMB_PATH = \"data/metric_name_embeddings.npy\"\n",
    "METRIC_NAMES_PATH = \"data/metric_names.json\"\n",
    "\n",
    "# Load metric embeddings\n",
    "metric_embeddings = np.load(METRIC_EMB_PATH) \n",
    "\n",
    "# Load metric names\n",
    "with open(METRIC_NAMES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    metric_names_list = json.load(f)  # usually a list of strings\n",
    "\n",
    "metric_name_to_idx = {\n",
    "    name: idx for idx, name in enumerate(metric_names_list)\n",
    "}\n",
    "\n",
    "# Load train & test JSON.\n",
    "with open(TRAIN_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_records = json.load(f)\n",
    "\n",
    "with open(TEST_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_records = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_records)\n",
    "test_df = pd.DataFrame(test_records)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the gemma model.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "with open(\"info.json\", \"r\") as file:\n",
    "    userdata = json.load(file)\n",
    "\n",
    "\n",
    "hf_token = userdata[\"hf_token\"]\n",
    "login(hf_token)\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bbe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384f575cb28e4238844428fe9ada0cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e44dfe3ced4b37a864d4571fb04d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train text embedding shape: (5000, 768)\n",
      "Test text embedding shape: (3638, 768)\n"
     ]
    }
   ],
   "source": [
    "# Build the combined full text data and encode.\n",
    "\n",
    "def build_text(df):\n",
    "    system = df.get(\"system_prompt\", pd.Series([\"\"] * len(df))).fillna(\"\")\n",
    "    prompt = df[\"user_prompt\"].fillna(\"\")\n",
    "    expected = df[\"response\"].fillna(\"\")\n",
    "    combined = (\n",
    "        \"System: \" + system.astype(str) + \" / Prompt: \" +\n",
    "        prompt.astype(str) + \" / Expected: \" + expected.astype(str)\n",
    "    )\n",
    "    return combined.tolist()\n",
    "\n",
    "train_texts = build_text(train_df)\n",
    "test_texts = build_text(test_df)\n",
    "\n",
    "train_text_emb = model.encode(\n",
    "    train_texts,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    ")\n",
    "test_text_emb = model.encode(\n",
    "    test_texts,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    ")\n",
    "\n",
    "print(\"Train text embedding shape:\", train_text_emb.shape)\n",
    "print(\"Test text embedding shape:\", test_text_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d135475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model embeddings.\n",
    "\n",
    "train_text_emb = np.load(\"text_train_embed_gpt.npy\")\n",
    "test_text_emb = np.load(\"text_test_embed_gpt.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e95cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metric embedding shape: (5000, 768)\n",
      "Test metric embedding shape: (3638, 768)\n"
     ]
    }
   ],
   "source": [
    "# Load the data.\n",
    "\n",
    "def get_metric_vectors(df):\n",
    "    indices = []\n",
    "    for m in df[\"metric_name\"]:\n",
    "        if m not in metric_name_to_idx:\n",
    "            raise ValueError(f\"Not Found\")\n",
    "        indices.append(metric_name_to_idx[m])\n",
    "    indices = np.array(indices, dtype=int)\n",
    "    return metric_embeddings[indices]\n",
    "\n",
    "train_metric_emb = get_metric_vectors(train_df)\n",
    "test_metric_emb = get_metric_vectors(test_df)\n",
    "\n",
    "print(\"Train metric embedding shape:\", train_metric_emb.shape)\n",
    "print(\"Test metric embedding shape:\", test_metric_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train feature shape: (5000, 3073)\n",
      "Final test feature shape: (3638, 3073)\n"
     ]
    }
   ],
   "source": [
    "# Build the metric data.\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def build_features(metric_vecs, text_vecs):\n",
    "    # Ensure same dimensionality\n",
    "    assert metric_vecs.shape == text_vecs.shape\n",
    "    \n",
    "    # Cosine similarity\n",
    "    dot = np.sum(metric_vecs * text_vecs, axis=1)\n",
    "    metric_norm = norm(metric_vecs, axis=1) + 1e-8\n",
    "    text_norm = norm(text_vecs, axis=1) + 1e-8\n",
    "    cos_sim = (dot / (metric_norm * text_norm)).reshape(-1, 1)  # (n, 1)\n",
    "    \n",
    "    # Absolute difference & elementwise product\n",
    "    diff = np.abs(metric_vecs - text_vecs)\n",
    "    prod = metric_vecs * text_vecs\n",
    "    \n",
    "    # Concatenate all\n",
    "    concat = np.concatenate([metric_vecs, text_vecs], axis=1)\n",
    "    feats = np.concatenate([concat, cos_sim, diff, prod], axis=1)\n",
    "    return feats\n",
    "\n",
    "X_train = build_features(train_metric_emb, train_text_emb)\n",
    "X_test = build_features(test_metric_emb, test_text_emb)\n",
    "\n",
    "print(\"Final train feature shape:\", X_train.shape)\n",
    "print(\"Final test feature shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d723ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3073) (1000, 3073) (4000,) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# SPlit the data into train and test.\n",
    "\n",
    "TARGET_COL = \"score\"\n",
    "\n",
    "y = train_df[TARGET_COL].astype(float).values\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(X_tr.shape, X_val.shape, y_tr.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.2049023\ttest: 2.3000434\tbest: 2.3000434 (0)\ttotal: 2.21s\tremaining: 29m 25s\n",
      "50:\tlearn: 0.5595752\ttest: 1.9961129\tbest: 1.9726655 (36)\ttotal: 4m 37s\tremaining: 1h 7m 58s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1.972665489\n",
      "bestIteration = 36\n",
      "\n",
      "Shrink model to first 37 iterations.\n",
      "CatBoost-fast val RMSE: 6.412910368417116\n",
      "0:\tlearn: 2.1685501\ttotal: 5.66s\tremaining: 3m 17s\n",
      "35:\tlearn: 0.7117490\ttotal: 3m 9s\tremaining: 0us\n",
      "CatBoost-fast full-train RMSE: 5.922565743592591\n"
     ]
    }
   ],
   "source": [
    "#Final Catboost classifier model.\n",
    "\n",
    "from collections import Counter\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "num_classes = 11\n",
    "y_int = train_df[\"score\"].astype(int).values\n",
    "\n",
    "# class weights \n",
    "cnt = Counter(y_int)\n",
    "total = len(y_int)\n",
    "class_weights = [total / (num_classes * cnt.get(c, 1)) for c in range(num_classes)]\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",\n",
    "    depth=6,\n",
    "    learning_rate=0.08,\n",
    "    iterations=800,\n",
    "    random_seed=42,\n",
    "    verbose=50,\n",
    "    class_weights=class_weights,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "clf.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "\n",
    "proba_val = clf.predict_proba(X_val)\n",
    "val_scores = (proba_val * np.arange(num_classes)).sum(axis=1)\n",
    "val_rmse = mean_squared_error(y_val, val_scores)\n",
    "print(\"CatBoost-fast val RMSE:\", val_rmse)\n",
    "\n",
    "best_iter = clf.get_best_iteration() or 800\n",
    "\n",
    "# train full model\n",
    "cb_full = CatBoostClassifier(\n",
    "    loss_function=\"MultiClass\",\n",
    "    depth=6,\n",
    "    learning_rate=0.08,\n",
    "    iterations=best_iter,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    class_weights=class_weights,\n",
    ")\n",
    "cb_full.fit(X_train, y_int)\n",
    "\n",
    "# probabilities on full train + test\n",
    "proba_train_cb = cb_full.predict_proba(X_train)\n",
    "proba_test_cb  = cb_full.predict_proba(X_test)\n",
    "\n",
    "train_scores_cb = (proba_train_cb * np.arange(num_classes)).sum(axis=1)\n",
    "print(\"CatBoost-fast full-train RMSE:\",\n",
    "      mean_squared_error(y_int, train_scores_cb))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
